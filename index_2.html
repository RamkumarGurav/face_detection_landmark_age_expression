<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Recognition</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <style>
        #webcam {
            display: block;
            margin: 0 auto;
        }
        #webcamCanvas {
            position: absolute;
            top: 0;
            left: 0;
        }
    </style>
</head>
<body>
    <video id="webcam" autoplay muted width="640" height="480"></video>
    <canvas id="webcamCanvas"></canvas>

    <script>
        // Load Face API models
        Promise.all([
            faceapi.nets.ssdMobilenetv1.loadFromUri('/models'), // Load face detection model
            faceapi.nets.faceLandmark68Net.loadFromUri('/models'), // Load face landmark model
            faceapi.nets.faceRecognitionNet.loadFromUri('/models') // Load face recognition model
        ]).then(startFaceRecognition);

        async function startFaceRecognition() {
            const video = document.getElementById('webcam');
            
            // Start the webcam stream
            navigator.mediaDevices.getUserMedia({ video: {} })
                .then(stream => {
                    video.srcObject = stream;
                });

            video.addEventListener('play', () => {
                const canvas = document.getElementById('webcamCanvas');
                const displaySize = { width: video.width, height: video.height };
                faceapi.matchDimensions(canvas, displaySize);

                setInterval(async () => {
                    const detections = await faceapi.detectAllFaces(video)
                        .withFaceLandmarks()
                        .withFaceDescriptors();
                    
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                    faceapi.draw.drawDetections(canvas, resizedDetections);
                    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

                    if (detections.length > 0) {
                        recognizeFace(detections[0].descriptor);
                    }
                }, 1000); // Check every second
            });
        }

        async function loadDatabaseImage(imageUrl) {
            const image = await faceapi.fetchImage(imageUrl);
            const detection = await faceapi.detectSingleFace(image).withFaceLandmarks().withFaceDescriptor();
            return detection.descriptor;
        }

        async function recognizeFace(webcamDescriptor) {
            const databaseImageDescriptor = await loadDatabaseImage('path_to_your_database_image.jpg');
            const faceMatcher = new faceapi.FaceMatcher(databaseImageDescriptor);
            const bestMatch = faceMatcher.findBestMatch(webcamDescriptor);
            console.log(bestMatch.toString()); // Output the result of the comparison
        }
    </script>
</body>
</html>
