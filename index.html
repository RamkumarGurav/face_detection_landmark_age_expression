<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <script defer src="face-api.min.js"></script>
   
</head>
<style>
    body{
    margin: 0;
    padding: 0;
    width: 100vw;
    height: 100vh;
    display: flex;
    justify-content: center;
    align-items: center;
}

canvas{
    position: absolute;
}
</style>
<body>
    <video id="video" width="640" height="480" autoplay muted></video>
</body>
<script>
window.addEventListener("load", function(){

        
    const video = document.getElementById("video");

Promise.all([
faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
faceapi.nets.faceLandmark68Net.loadFromUri("/models"),
faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
// faceapi.nets.faceExpressionNet.loadFromUri("/models"),
// faceapi.nets.ageGenderNet.loadFromUri("/models"),
]).then(webCam);

function webCam() {
navigator.mediaDevices
.getUserMedia({
  video: true,
  audio: false,
})
.then((stream) => {
  video.srcObject = stream;
})
.catch((error) => {
  console.log(error);
});
}

video.addEventListener("play", () => {
const canvas = faceapi.createCanvasFromMedia(video);
document.body.append(canvas);

faceapi.matchDimensions(canvas, { height: video.height, width: video.width });

const tinyFaceDetectorOptions = new faceapi.TinyFaceDetectorOptions({
inputSize: 160,  // Smaller size for faster detection (default is 320)
scoreThreshold: 0.5, // Increase threshold for faster processing
});

setInterval(async () => {
const detection = await faceapi
  .detectAllFaces(video, tinyFaceDetectorOptions)
  .withFaceLandmarks()
  // .withFaceExpressions()
  // .withAgeAndGender();

canvas.getContext("2d").clearRect(0, 0, canvas.width, canvas.height);

const resizedResults = faceapi.resizeResults(detection, {
  height: video.height,
  width: video.width,
});

faceapi.draw.drawDetections(canvas, resizedResults);
faceapi.draw.drawFaceLandmarks(canvas, resizedResults);
// faceapi.draw.drawFaceExpressions(canvas, resizedResults);

resizedResults.forEach((detection) => {
  const box = detection.detection.box;
  const drawBox = new faceapi.draw.DrawBox(box, {
    // label: detection.gender,
  });
  drawBox.draw(canvas);
});

console.log(detection);
}, 50); // Reduced interval for quicker detection
});
})

</script>
</html>